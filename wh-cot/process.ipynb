{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "def main():\n",
    "    # # Load JSON file\n",
    "    # file_path = 'E:\\LLM\\zero-shot-cot-cmk\\dataset\\gsm8k/test.json'\n",
    "\n",
    "    # # 加载数据\n",
    "    # with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    #     data = json.load(file)\n",
    "\n",
    "    # Load JSONl file\n",
    "    file_path = 'E:\\LLM\\zero-shot-cot-cmk\\dataset\\gsm8k/test.jsonl'\n",
    "\n",
    "    # 加载数据\n",
    "    data=[]\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            sample = json.loads(line.strip())\n",
    "            data.append(sample)\n",
    "\n",
    "\n",
    "    # 随机打乱数据\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # 从打乱后的数据中分割出训练样本和测试样本\n",
    "    train_data = data[:300]\n",
    "    test_data = data[300:1300]\n",
    "\n",
    "    # # 保存训练样本和测试样本到json文件中\n",
    "    # with open(\"gsm8k_train_samples.json\", 'w', encoding='utf-8') as train_file:\n",
    "    #     json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "    # with open(\"gsm8k-test.json\", 'w', encoding='utf-8') as test_file:\n",
    "    #     json.dump(test_data, test_file, indent=4)\n",
    "    \n",
    "    # 保存训练样本和测试样本到jsonl文件中\n",
    "    with open(\"gsm8k_train_samples.jsonl\", 'w', encoding='utf-8') as train_file:\n",
    "        for i in train_data:\n",
    "            json.dump(i,train_file)\n",
    "            train_file.write('\\n')\n",
    "    \n",
    " \n",
    "    with open(\"gsm8k-test.jsonl\", 'w', encoding='utf-8') as f:\n",
    "        for i in test_data:\n",
    "            json.dump(i,f)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "#测试数据\n",
    "#每一类随机选择x条数据\n",
    "or_data = []\n",
    "\n",
    "file_path = 'dataset/train\\svamp_train.json'\n",
    "with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "    or_data = json.load(file)\n",
    "#print (or_data)\n",
    "for cluster_data in or_data:\n",
    "    cluster_data[\"train_samples\"] = random.sample(cluster_data[\"train_samples\"], 15)\n",
    "\n",
    "save_path = './dataset/train/svamp_train_120.json'\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(or_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#生成cot的文件，改造成分簇的\n",
    "# Read the jsonl file\n",
    "jsonl_file_path = './demo\\strategyqa/202403262021/demo_dataset.json'\n",
    "with open(jsonl_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "samples_per_cluster = 30\n",
    "\n",
    "# 将样本数据按照cluster_id分组\n",
    "clusters = []\n",
    "for i in range(0, len(data), samples_per_cluster):\n",
    "    cluster_data = {\n",
    "        \"cluster_id\": i // samples_per_cluster,\n",
    "        \"train_samples\": data[i:i + samples_per_cluster]\n",
    "    }\n",
    "    clusters.append(cluster_data)\n",
    "\n",
    "print(clusters)\n",
    "\n",
    "# Convert the clustered data to JSON format and print it\n",
    "json_file_path = './demo\\strategyqa/202403262021/demo_dataset.json'\n",
    "with open(json_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(clusters, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "question_embedding = [\n",
    "                    0.010228211060166359,\n",
    "                    0.03918223828077316,\n",
    "                    0.06935285776853561\n",
    "                ]\n",
    "demo_dataset_path = 'E:\\LLM\\zero-shot-cot-cmk\\demo\\strategyqa\\demo_embedding.json'\n",
    "demo_num = 2\n",
    "with open(demo_dataset_path, 'r',encoding=\"utf-8\") as f:\n",
    "        demo_datas = json.load(f)\n",
    "    \n",
    "question_embedding = np.array(question_embedding, dtype=float)\n",
    "\n",
    "# 定义一个存放测试问题与所有demo问题的相似度的列表\n",
    "similarity_list = []\n",
    "for cluster_idx in range(len(demo_datas)):\n",
    "    #print(demo_datas[cluster_idx])\n",
    "    train_samples = demo_datas[cluster_idx][\"train_samples\"]\n",
    "    inner_similarity_list = []\n",
    "    for sample_idx in range(len(train_samples)):\n",
    "        # 计算当前测试问题的embedding与遍历到的demo问题的embedding的相似度\n",
    "        demo_embedding = np.array(train_samples[sample_idx][\"embedding\"], dtype=float)\n",
    "        similarity = util.cos_sim(question_embedding, demo_embedding)[0, 0]\n",
    "        inner_similarity_list.append(similarity)\n",
    "    similarity_list.append(inner_similarity_list)\n",
    "# 找到最长的相似度列表的长度\n",
    "max_len = max(len(similarity_list[i]) for i in range(len(similarity_list)))\n",
    "# 对齐长度并填充0\n",
    "for i in range(len(similarity_list)):\n",
    "    similarity_list[i] += [0] * (max_len - len(similarity_list[i]))\n",
    "# 将相似度列表转换成numpy数组\n",
    "similarity_array = np.array(similarity_list)\n",
    "#print(similarity_array)\n",
    "# 找到这个二维列表中最相似的demo_num个问题的索引，也就是找到这个二维列表中值最大的demo_num个值的索引\n",
    "x = 1 + demo_num\n",
    "index = np.argsort(similarity_array.ravel())[:-x:-1]\n",
    "positions = np.unravel_index(index, similarity_array.shape)\n",
    "positions_2d = np.column_stack(positions)\n",
    "# pos_positions = copy.deepcopy(positions_2d.tolist())\n",
    "# print(pos_positions)\n",
    "question_demonstrations = []\n",
    "sample_pre = {}\n",
    "for i in range(len(positions_2d)):\n",
    "        indexs = positions_2d[i]\n",
    "        cluster_id = indexs[0]\n",
    "        sample_id = indexs[1]\n",
    "        sample = demo_datas[cluster_id][\"train_samples\"][sample_id]\n",
    "        if similarity_array[cluster_id, sample_id] != 0:\n",
    "              sample_pre = {\n",
    "             \"question\" : sample[\"question\"],\n",
    "             \"elements\" : sample[\"elements\"],\n",
    "             \"questions\" : sample[\"questions\"],\n",
    "             \"cot\" : sample[\"cot\"],\n",
    "             \"answer\" : sample[\"gold_ans\"]\n",
    "        }\n",
    "        question_demonstrations.append(sample_pre)\n",
    "\n",
    "print(question_demonstrations)\n",
    "#print(question_demonstrations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从网页下载数据集\n",
    "import requests\n",
    "\n",
    "# 定义数据集的URL\n",
    "url = \"https://dl.fbaipublicfiles.com/KILT/eli5-dev-kilt.jsonl\"\n",
    "\n",
    "# 发送HTTP GET请求以下载数据集\n",
    "response = requests.get(url)\n",
    "\n",
    "# 检查请求状态\n",
    "if response.status_code == 200:\n",
    "    # 保存数据集到本地文件\n",
    "    with open(\"eli5-dev-kilt.jsonl\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"数据集下载成功！\")\n",
    "else:\n",
    "    print(\"数据集下载失败。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import pd\n",
    "from nltk import PorterStemmer\n",
    "from rouge import Rouge\n",
    "from spacy.lang.en import English\n",
    "from time import time\n",
    "import nlp\n",
    "\n",
    "predicted = [\"The traces left by the tail of an aircraft during high-altitude flight, commonly known as wake or contrails, are mainly formed by the high-temperature exhaust emitted by the aircraft meeting the cold air at high altitude. Aircraft engines burn fuel, producing high-temperature and high-pressure gases that contain water vapor when discharged. When these high-temperature water vapor encounter cold air at high altitudes (usually between -40 ℃ and -60 ℃), the water vapor quickly cools and condenses into small water droplets or ice crystals, forming visible white or gray cloud like traces. This process is called condensation nucleation and is a common natural phenomenon in flight. When the aircraft speed is fast enough and the atmospheric conditions are suitable, the wake will be more pronounced.\"]\n",
    "reference = [\"It is water vapor and ice. They are produced from the hot engine exhaust in the cold atmosphere. Water vapor from the engine exhaust mixed with unburnt particulate in the jet fuel gives the surrounding moist air something to latch onto and ice crystals form. Depending on the hight of the aircraft, they can last seconds to hours. If you have seen a running car on a brisk morning, that is a similar effect. The car is too close to the relatively warmer ground that trails do not last for more than a second.\"]\n",
    "\n",
    "# Compare each generation to the fist answer from the dataset\n",
    "nlp_rouge = nlp.load_metric('rouge')\n",
    "\n",
    "scores = nlp_rouge.compute(\n",
    "    predicted, reference,\n",
    "    rouge_types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "    use_agregator=True, use_stemmer=False\n",
    ")\n",
    "df = pd.DataFrame({\n",
    "    'rouge1': [scores['rouge1'].mid.precision, scores['rouge1'].mid.recall, scores['rouge1'].mid.fmeasure],\n",
    "    'rouge2': [scores['rouge2'].mid.precision, scores['rouge2'].mid.recall, scores['rouge2'].mid.fmeasure],\n",
    "    'rougeL': [scores['rougeL'].mid.precision, scores['rougeL'].mid.recall, scores['rougeL'].mid.fmeasure],\n",
    "}, index=[ 'P', 'R', 'F'])\n",
    "df.style.format({'rouge1': \"{:.4f}\", 'rouge2': \"{:.4f}\", 'rougeL': \"{:.4f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "pred = \"==================is 11111 .  60%  ;  has 10 p as folles toni has 16 planta -7 Shondra has 9 plants 12121.==================\"\n",
    "task = \"gsm8k\"\n",
    "method = \"few_shot_cot\"\n",
    "\n",
    "if method in (\"few_shot\", \"few_shot_cot\"):\n",
    "    preds = pred.split(\"==================\")\n",
    "    answer_flag = True if len(preds) > 1 else False \n",
    "    pred = preds[-1]\n",
    "    print(preds)\n",
    "    print(answer_flag)\n",
    "    print(pred)\n",
    "# pred = pred.split('60% ')[-1]\n",
    "# print(pred)\n",
    "# print('==========================')\n",
    "# pred = pred.split('has 16')[-1]\n",
    "# print(pred)\n",
    "# print('==========================')\n",
    "\n",
    "\n",
    "if task in (\"aqua\", \"commonsensqa\"):\n",
    "    pred = pred.split('Therefore,')[-1]\n",
    "    pred = pred.split('answer to the question is')[-1]\n",
    "    pred = pred.split('answer is')[-1]\n",
    "    pred = re.findall(r'A|B|C|D|E', pred)\n",
    "\n",
    "elif task in (\"gsm8k\", \"addsub\", \"multiarith\", \"svamp\", \"singleeq\"):\n",
    "    pred = pred.replace(\",\", \"\")\n",
    "    pred = [s for s in re.findall(r'-?\\d+\\.?\\d*', pred)]\n",
    "    #print(\"============\")\n",
    "    #print(pred)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"dataset is not properly defined ...\")\n",
    "\n",
    "# If there is no candidate in list, null is set.\n",
    "if len(pred) == 0:\n",
    "    pred = \"\"\n",
    "else:\n",
    "    if method in (\"few_shot\", \"few_shot_cot\"):\n",
    "        #为真，意味着有\"the final answer (arabic numerals) is\"，且分成多段，并选取最后一段\n",
    "        if answer_flag:\n",
    "            # choose the first element in list ...\n",
    "            pred = pred[0]\n",
    "        else:\n",
    "            # choose the last element in list ...\n",
    "            pred = pred[-1]\n",
    "    elif method in (\"zero_shot\", \"zero_shot_cot\"):\n",
    "        # choose the first element in list ...\n",
    "        pred = pred[0]\n",
    "    else:\n",
    "        raise ValueError(\"method is not properly defined ...\")\n",
    "\n",
    "# (For arithmetic tasks) if a word ends with period, it will be omitted ...\n",
    "if pred != \"\":\n",
    "    if pred[-1] == \".\":\n",
    "        pred = pred[:-1]\n",
    "\n",
    "print(\"pred_after : \" + pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = \"Trina, Eve, Remy Ma, Lil Kim, and Gucci Mane(ds dssdsdsds) 20 xxx\"\n",
    "predddd = [s for s in re.findall(r'-?\\d+\\.?\\d*', pred)]\n",
    "print(predddd)\n",
    "predddd = predddd[-1]\n",
    "\n",
    "print(predddd)\n",
    "pred = re.sub(\"\\([^)]*\\)\", \"\", pred)\n",
    "print(pred)\n",
    "#pred = re.split(\", | and | or |/| either \", pred)\n",
    "print(pred)\n",
    "preds = str((pred))\n",
    "print(preds)\n",
    "x = \"Trina, Eve, Remy Ma, Lil Kim, and Gucci Mane 20 xxx\"\n",
    "if preds == x:\n",
    "    print(\"dddddd\")\n",
    "    \n",
    "else:\n",
    "    print(\"nnnnnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_answer(raw_pred: str):\n",
    "    if raw_pred == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    # find yes or no\n",
    "    yes_no_answer = check_answer(raw_pred)\n",
    "    if yes_no_answer is not None:\n",
    "        return yes_no_answer\n",
    "\n",
    "    # remove the words in ()\n",
    "    raw_pred = re.sub(\"\\([^)]*\\)\", \"\", raw_pred)\n",
    "    #answers = re.split(\", | and | or |/| either \", raw_pred)\n",
    "\n",
    "    return raw_pred\n",
    "\n",
    "\n",
    "def check_answer(text):\n",
    "    pattern = r\"^(yes|no)[,.]?\"\n",
    "    match = re.match(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        answer = match.group(0).lower()  # Get the matched string in lowercase\n",
    "        answer = re.sub(r'[,.]', '', answer)  # Remove punctuation\n",
    "        return answer\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "pred = \"59\"\n",
    "predd = extract_answer(pred)\n",
    "print(extract_answer(predd))\n",
    "sample = \"59\"\n",
    "\n",
    "correct = (np.array([predd]) == np.array([sample])).sum().item()\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = \"The question seems to be mixing up two different individuals or concepts. Kalle Mäkinen is a Finnish ice hockey player, not a Spanish football player. Therefore, it would not make sense for him to have a nickname related to a Spanish football captaining teams, as that is not his field of sports.However, if there's a misunderstanding and the intention is to refer to a football player with a similar nickname, we still need more context to provide an accurate answer. If 'Kalle Mäkinen' is a fictional character or a nickname used metaphorically, the connection to a Spanish football player might be a creative association.If the focus is on a football player with a similar nickname, we would need to know the specific nickname in question to determine which player it refers to and their teams. Without that information, we cannot answer this question accurately.Given the context provided, the answer to the original question remains unclear. If the question is about Kalle Mäkinen's nickname in relation to a football player, please clarify the connection or provide more details. If it's about the ice hockey player, then the answer is that Kalle Mäkinen is not a football player, so he doesn't captain any football teams.\"\n",
    "task = 'hotpot'\n",
    "method = \"wh-cot\"\n",
    "\n",
    "if task in ('gsm8k'):\n",
    "    answer_trigger = \"Therefore, the answer (decimal numerals) is\"\n",
    "elif task in ('aqua'):\n",
    "    answer_trigger = \"Therefore, among A through E, the answer is\"\n",
    "elif task in ('hotpot','musique'):\n",
    "    answer_trigger = \"Therefore, the answer is\"\n",
    "\n",
    "\n",
    "if method in (\"wh-cot\",\"few_shot\", \"few_shot_cot\"):\n",
    "    preds = pred.split(answer_trigger)\n",
    "    answer_flag = True if len(preds) > 1 else False \n",
    "    pred = preds[-1]\n",
    "\n",
    "if task in (\"aqua\", \"commonsensqa\"):\n",
    "    pred = pred.split('answer to the question is')[-1]\n",
    "    pred = pred.split('answer is')[-1]\n",
    "    pred = re.findall(r'A|B|C|D|E', pred)\n",
    "\n",
    "elif task in (\"gsm8k\", \"addsub\", \"multiarith\", \"svamp\", \"singleeq\"):\n",
    "    pred = pred.split('answer to the question is')[-1]\n",
    "    pred = pred.split('answer is')[-1]\n",
    "    pred = pred.replace(\",\", \"\")\n",
    "    pred = [s for s in re.findall(r'-?\\d+\\.?\\d*', pred)]\n",
    "\n",
    "elif task in ('hotpot','musique'):\n",
    "    pred = pred.split('the answer is:')[-1]\n",
    "    pred = pred.split('answer to the question is')[-1]\n",
    "    pred = pred.split('The answer would be')[-1]\n",
    "    pred = pred.split('answer is')[-1]\n",
    "    pred = pred.split('Answer:')[-1]\n",
    "    pred = pred.strip(':')\n",
    "    print(pred)\n",
    "    pred = [pred]\n",
    "    print(pred)\n",
    "else:\n",
    "    raise ValueError(\"dataset is not properly defined ...\")\n",
    "\n",
    "if len(pred) == 0:\n",
    "    pred = \"\"\n",
    "else:\n",
    "    if method in (\"few_shot\", \"few_shot_cot\", \"wh-cot\"):\n",
    "        if answer_flag:\n",
    "            # choose the first element in list ...\n",
    "            pred = pred[0]\n",
    "            print(\"ddddd\")\n",
    "            print(pred)\n",
    "        else:\n",
    "            # choose the last element in list ...\n",
    "            pred = pred[0]\n",
    "            print(\"xxxxx\")\n",
    "            print(pred)\n",
    "    elif method in (\"zero_shot\", \"zero_shot_cot\"):\n",
    "        # choose the first element in list ...\n",
    "        pred = pred[0]\n",
    "    else:\n",
    "        raise ValueError(\"method is not properly defined ...\")\n",
    "    \n",
    "# (For arithmetic tasks) if a word ends with period, it will be omitted ...\n",
    "if pred != \"\":\n",
    "    if pred[-1] == \".\":\n",
    "        pred = pred[:-1]\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "pred = \"Frederick I, also known as Frederick Barbarossa, is the grandfather to Frederick II and was the Holy Roman Emperor until his death in 1190\"\n",
    "gold_ans = \"Frederick I\"\n",
    "pred = extract_answer(pred)\n",
    "\n",
    "prediction_tokens = normalize_answer(pred).split()\n",
    "print(f\"prediction_tokens: {prediction_tokens}\")\n",
    "ground_truth_tokens = normalize_answer(gold_ans).split()\n",
    "print(f\"ground_truth_tokens: {ground_truth_tokens}\")\n",
    "\n",
    "f1_score = compute_f1(pred,gold_ans)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'wh-cot'\n",
    "#pred = \"Step 1: Key elements of the question:Silu, Meenu, walking on the road.Step 2: Decompose the question into new questions:1. Who are Silu and Meenu?2. Are Silu and Meenu related to each other?3. Where are Silu and Meenu located?4. What are Silu and Meenu doing?5. Is there any context or background information available about Silu and Meenu?Step 3: Analyzing these new questions can inferr that:Silu and Meenu are two individuals mentioned in the question. It is not specified whether they are related or not. The location of Silu and Meenu is on a road. They are engaged in the activity of walking. There is no additional context or background information provided about Silu and Meenu.In conclusion, based on the given information, Silu and Meenu are two people who are currently walking on a road. No further details about their relationship or background are provided.\"\n",
    "pre = 2.00\n",
    "sample = 114,200\n",
    "answer_trigger = \"Therefore, among A through E, the answer is\"\n",
    "\n",
    "if method in (\"wh-cot\",\"few_shot\", \"few_shot_cot\"):\n",
    "    preds = pred.split(answer_trigger)\n",
    "    answer_flag = True if len(preds) > 1 else False \n",
    "    pred = preds[-1]\n",
    "\n",
    "pred = pred.split('answer to the question is')[-1]\n",
    "pred = pred.split('answer is')[-1]\n",
    "pred = re.findall(r'A|B|C|D|E', pred)\n",
    "print(pred)\n",
    "if len(pred) == 0:\n",
    "        pred = \"\"\n",
    "else:\n",
    "    if method in (\"few-shot\", \"few-shot-cot\", \"wh-cot\"):\n",
    "        if answer_flag:\n",
    "            # choose the first element in list ...\n",
    "            pred = pred[0]\n",
    "        else:\n",
    "            # choose the last element in list ...\n",
    "            pred = pred[-1]\n",
    "    elif method in (\"zero-shot\", \"zero-shot-cot\"):\n",
    "        # choose the first element in list ...\n",
    "        pred = pred[0]\n",
    "    else:\n",
    "        raise ValueError(\"method is not properly defined ...\")\n",
    "    \n",
    "# (For arithmetic tasks) if a word ends with period, it will be omitted ...\n",
    "if pred != \"\":\n",
    "    if pred[-1] == \".\":\n",
    "        pred = pred[:-1]\n",
    "#correct = (np.array([pred]) == np.array(sample)).sum().item()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = \"43500\"\n",
    "gold_ans = \"\"\n",
    "gold_ans = gold_ans.replace(\",\", \"\")\n",
    "pre= float(pre)\n",
    "gold_ans = float(gold_ans)\n",
    "print(gold_ans)\n",
    "print(pre)\n",
    "\n",
    "correct = (np.array([pre]) == np.array(gold_ans)).sum().item()\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import time\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-7lDeR2hYGD3VwH2P509c67Bb0093478eA790641c19073964\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = 'https://api.gptapi.us/v1'\n",
    "\n",
    "def decoder_for_gpt3(model,input):\n",
    "    # GPT-3 API allows each users execute the API within 60 times in a minute ...\n",
    "    time.sleep(2)\n",
    "\n",
    "    #switch_key()\n",
    "    model = model\n",
    "    #model = \"gpt-3.5-turbo\"\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    )\n",
    "    response = None\n",
    "    try:\n",
    "        response = request_chat(client,model, input)\n",
    "    except openai.APIStatusError as e:\n",
    "        if e.status_code == 407:\n",
    "            # 休眠2.5秒\n",
    "            time.sleep(5)\n",
    "            response = request_chat(client,model, input)\n",
    "        else:\n",
    "            print(e)\n",
    "    except AttributeError as exception:\n",
    "        time.sleep(5)\n",
    "        response = request_chat(client, model, input)\n",
    "        # print(exception)\n",
    "        # print(type(exception))\n",
    "        \n",
    "    if response != None:\n",
    "        print(\"====================\")\n",
    "        print(response)\n",
    "        print(\"====================\")\n",
    "        return response.choices[0].message.content\n",
    "    else:\n",
    "        return response\n",
    "\n",
    "def request_chat(client,model,input):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        max_tokens=1500,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    return response\n",
    "\n",
    "input = \"Lorie earns $10 per hour. Karen earns twice what Lorie earns. How much does Karen earn in two days if she works 3 hours per day?\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "response = decoder_for_gpt3(model, input)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 读取日志文件\n",
    "with open('./eval-log\\qwen-14b-chat/2wikim/0403-143500-2wikim-zero-shot.log', 'r') as file:\n",
    "    log_content = file.read()\n",
    "\n",
    "# 定义正则表达式模式来匹配 EM 和 F1 分数\n",
    "em_pattern = r'EM:\\s*([\\d.]+)'\n",
    "f1_pattern = r'F1:\\s*([\\d.]+)'\n",
    "\n",
    "# 使用 findall() 方法来找到所有匹配的 EM 和 F1 分数\n",
    "em_scores = re.findall(em_pattern, log_content)\n",
    "f1_scores = re.findall(f1_pattern, log_content)\n",
    "\n",
    "all_f1 = 0\n",
    "all_em = 0\n",
    "\n",
    "for i in range(len(f1_scores)):\n",
    "\n",
    "    all_f1 += float(f1_scores[i])\n",
    "    all_em += float(em_scores[i])\n",
    "\n",
    "# 打印提取的分数\n",
    "#print(\"EM scores:\", em_scores)\n",
    "#print(\"F1 scores:\", f1_scores)\n",
    "print(len(f1_scores))\n",
    "print(\"EM :\", all_em * 100 / len(f1_scores))\n",
    "print(\"F1 :\", all_f1 * 100 / len(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 对于hoptpot\n",
    "# 从每簇中采样与question最相似的问题\n",
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import dashscope\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from utils import *\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def get_sentence_encoder():\n",
    "    model = \"all-MiniLM-L6-v2\"\n",
    "    return SentenceTransformer(model)\n",
    "encoder = get_sentence_encoder()\n",
    "#当前question属于cluster_id\": 0\n",
    "question = \"Seven years before the opening of the Brewer Fieldhouse in Columbia, Missouri, where was Chester Brewer working as head football coach and head basketball coach?\"\n",
    "question_embedding = encoder.encode(question)\n",
    "dataset_path = './demos/hotpot/demo_embedding.json'\n",
    "demo_num = 3\n",
    "\n",
    "#读取该任务的语料库\n",
    "with open(dataset_path, 'r',encoding=\"utf-8\") as f:\n",
    "    demo_datas = json.load(f)\n",
    "\n",
    "question_embedding = np.array(question_embedding, dtype=float)\n",
    "\n",
    "# 定义一个存放测试问题与所有demo问题的相似度的列表\n",
    "similarity_list = []\n",
    "for cluster_idx in range(len(demo_datas)):\n",
    "    #print(demo_datas[cluster_idx])\n",
    "    train_samples = demo_datas[cluster_idx][\"train_samples\"]\n",
    "    max_similarity = -1\n",
    "    most_similar_sample = None\n",
    "    for sample in train_samples:\n",
    "        # 计算当前测试问题的embedding与该簇中的demo问题的embedding的相似度\n",
    "        demo_embedding = np.array(sample[\"embedding\"], dtype=float)\n",
    "        similarity = util.cos_sim(question_embedding, demo_embedding)[0, 0]\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar_sample = sample\n",
    "    if most_similar_sample is not None:\n",
    "        similarity_list.append(most_similar_sample)\n",
    "\n",
    "#print(len(similarity_list))\n",
    "# 将选择的问题按相似度排序\n",
    "similarity_list.sort(key=lambda x:util.cos_sim(question_embedding, np.array(x[\"embedding\"], dtype=float)), reverse=True)\n",
    "\n",
    "# 选择最相似的3个问题\n",
    "most_similar_questions = similarity_list[:demo_num]\n",
    "print(\"*************most_similar_questions***********\")\n",
    "print(most_similar_questions)\n",
    "\n",
    "question_demonstrations = []\n",
    "for sample in most_similar_questions:\n",
    "    sample_pre = {\n",
    "    \"question\" : sample[\"question\"],\n",
    "    \"elements\" : sample[\"elements\"],\n",
    "    \"questions\" : sample[\"questions\"],\n",
    "    \"cot\" : sample[\"cot\"],\n",
    "    \"answer\" : sample[\"gold_ans\"]\n",
    "    }\n",
    "    question_demonstrations.append(sample_pre)\n",
    "print(\"*************question_demonstrations***********\")\n",
    "print(question_demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************question_demonstrations***********\n",
      "[{'question': 'Which player, who also played for the New Jersey Nets and the Golden State Warriors, finished third in the league with 231 three-point field goals during the 1995-96 Atlanta Hawks season?', 'elements': 'player, New Jersey Nets, Golden State Warriors, finished third, league, 231 three-point field goals, 1995-96 Atlanta Hawks season.', 'questions': \"1. Who is the player that achieved this milestone?\\n2. Why was this player chosen to be mentioned for this particular accomplishment?\\n3. Which team did the player join after the 1995-96 season?\\n4. How did the player's performance in three-point field goals contribute to their ranking in the league that year?\\n5. In which position did the player finish in the league's overall scoring during that season?\\n6. Can you provide more details on the player's statistics and impact during the 1995-96 Atlanta Hawks season?\", 'cot': \"In the 1995-96 NBA season, the player who achieved a significant milestone was none other than Allen Iverson. Iverson, known for his exceptional skills and competitive spirit, was selected for this recognition due to his outstanding performance that year. After the previous season, he joined the Atlanta Hawks, where his impact on the court became evident.\\n\\nDuring the 1995-96 campaign, Iverson showcased his prowess in three-point field goals, contributing significantly to his overall scoring prowess. His ability to drain threes from beyond the arc made him a formidable force in the league. As a result, his impressive shooting percentages led him to rank highly in the league's three-point statistics.\\n\\nThat season, Iverson's exceptional scoring abilities propelled him to finish in the top spot in the league's overall scoring, solidifying his status as one of basketball's elite players. His combined scoring, playmaking, and clutch performances not only earned him individual accolades but also lifted the Atlanta Hawks to new heights during that memorable season.\", 'answer': 'Mookie Blaylock'}, {'question': 'Which FC Barcelona signee was a contender for the Rookie of the Year Award when he played for the Timberwolves?', 'elements': 'FC Barcelona signee, Rookie of the Year Award, played for the Timberwolves.', 'questions': \"1. Who is the FC Barcelona player that received recognition as a Rookie of the Year Award nominee?\\n2. In what year was the FC Barcelona signee considered for the Rookie of the Year Award while playing for the Timberwolves?\\n3. Which basketball position did this FC Barcelona player play when he joined the Timberwolves?\\n4. How did the player's performance contribute to their nomination for the Rookie of the Year Award?\\n5. Was this player the first FC Barcelona player to join the Timberwolves, or were there others before him?\\n6. What impact did the player have on the Timberwolves team during the time they were a Rookie of the Year contender?\", 'cot': \"Passage: The FC Barcelona player who gained recognition as a Rookie of the Year Award nominee is a basketball talent. In the year 2015, this signee, who initially played for the Minnesota Timberwolves, was considered for the prestigious award. During his time with the Timberwolves, he displayed exceptional skills at the shooting guard position. His impressive performance, characterized by strong scoring and impactful contributions to the team's success, led to his nomination. Although not the first FC Barcelona player to join the Timberwolves, this individual's arrival marked a notable moment for the team, as they saw potential in a player with international roots. As a Rookie of the Year contender, he significantly bolstered the team's chances and showcased his talents on the court.\", 'answer': 'Ricard Rubio i Vives'}, {'question': 'Steve Denton and Albert Costa are both tennis players, which one began playing at the age if five?', 'elements': 'Steve Denton, Albert Costa, tennis players, age of five.', 'questions': \"1. Who is the tennis player that started playing at the age of five between Steve Denton and Albert Costa?\\n2. Which of the two mentioned tennis players, Steve Denton or Albert Costa, had an early beginning with the sport at the age of five?\\n3. Can you provide information on the age at which Steve Denton began playing tennis in comparison to Albert Costa?\\n4. In terms of their tennis career beginnings, when did Steve Denton commence his training, and how does it compare to Albert Costa's start at the age of five?\\n5. Between Steve Denton and Albert Costa, who is known for having a late start or an early start in their tennis journey, specifically at the age of five?\\n6. What is the significance of the age of five in the development of Steve Denton's and Albert Costa's tennis careers, and which player started at that age?\", 'cot': \"Passage: The tennis player who started playing at the tender age of five was Albert Costa, out of the two mentioned players, Steve Denton and Albert Costa. Albert's early beginning with the sport at such a young age marked a significant headstart compared to Steve, who had a later start in his tennis journey. While的具体年龄对比史蒂夫·邓顿何时开始训练的信息并未在问题中给出，但可以确定的是，他的起步时间显然晚于Albert Costa，后者在五岁时就已经展开了网球训练。因此，在网球生涯的早期阶段，阿尔伯特·科斯塔以五岁这个年龄为分水岭，展现出了明显的优势。\", 'answer': 'Costa'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 对于hoptpot\n",
    "# 在question所在簇中，随机采样\n",
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import dashscope\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from utils import *\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def get_sentence_encoder():\n",
    "    model = \"all-MiniLM-L6-v2\"\n",
    "    return SentenceTransformer(model)\n",
    "encoder = get_sentence_encoder()\n",
    "#当前question属于cluster_id\": 0\n",
    "question = \"Seven years before the opening of the Brewer Fieldhouse in Columbia, Missouri, where was Chester Brewer working as head football coach and head basketball coach?\"\n",
    "question_embedding = encoder.encode(question)\n",
    "dataset_path = './demos/hotpot/demo_embedding.json'\n",
    "demo_num = 3\n",
    "cluster_id = 0\n",
    "\n",
    "#读取该任务的语料库\n",
    "with open(dataset_path, 'r',encoding=\"utf-8\") as f:\n",
    "    demo_datas = json.load(f)\n",
    "\n",
    "cluster_samples = demo_datas[cluster_id][\"train_samples\"]\n",
    "\n",
    "random_samples = random.sample(cluster_samples,demo_num)\n",
    "\n",
    "# 选择3个问题\n",
    "question_demonstrations = []\n",
    "for sample in random_samples:\n",
    "    sample_pre = {\n",
    "    \"question\" : sample[\"question\"],\n",
    "    \"elements\" : sample[\"elements\"],\n",
    "    \"questions\" : sample[\"questions\"],\n",
    "    \"cot\" : sample[\"cot\"],\n",
    "    \"answer\" : sample[\"gold_ans\"]\n",
    "    }\n",
    "    question_demonstrations.append(sample_pre)\n",
    "print(\"*************question_demonstrations***********\")\n",
    "print(question_demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "*************question_demonstrations***********\n",
      "[{'question': \"How did Emilie du Chatelet, Voltaire's love, contribute to the basic laws of physics?\", 'elements': \"Emilie du Chatelet, Voltaire's love, contribution, basic laws of physics.\", 'questions': '1. Who is Emilie du Chatelet?\\n2. Why was she significant to Voltaire?\\n3. In what context did their relationship influence her work?\\n4. What specific contributions did Emilie make to the field of physics?\\n5. How were her discoveries related to the development of the basic laws of physics?\\n6. To what extent did her work challenge or advance scientific thought during her time?', 'cot': 'Emilie du Châtelet, a prominent 18th-century French philosopher and mathematician, played a significant role in the intellectual circles of her time, particularly for her influential relationship with the Enlightenment thinker Voltaire. As a correspondent and intellectual partner, their connection deeply impacted her work, inspiring her to delve into the scientific domain, especially physics.\\n\\nVoltaire admired du Châtelet\\'s intellect and encouraged her to study and translate Sir Isaac Newton\\'s groundbreaking treatise, \"Principia Mathematica.\" Through this collaboration, she gained a deep understanding of Newton\\'s laws, which she applied to her own research. Du Châtelet made notable contributions to the field by translating and explaining Newton\\'s ideas to a broader audience, making them more accessible to French scientists.\\n\\nHer most significant achievement in physics was her translation and commentary on Newton\\'s \"Principia,\" where she clarified complex mathematical concepts and provided a more intuitive explanation of the fundamental laws of motion and universal gravitation. By doing so, she challenged the prevalent Aristotelian views and advanced the scientific understanding of the time. Her work, therefore, played a pivotal role in shaping modern physics, demonstrating the power of reason and empirical evidence over traditional philosophical beliefs. Du Châtelet\\'s groundbreaking contributions laid the groundwork for future scientists and helped pave the way for the scientific revolution that would define the Enlightenment era.', 'answer': 'commentary on Isaac Newton\\'s book \"Principia\"'}, {'question': 'Steve Denton and Albert Costa are both tennis players, which one began playing at the age if five?', 'elements': 'Steve Denton, Albert Costa, tennis players, age of five.', 'questions': \"1. Who is the tennis player that started playing at the age of five between Steve Denton and Albert Costa?\\n2. Which of the two mentioned tennis players, Steve Denton or Albert Costa, had an early beginning with the sport at the age of five?\\n3. Can you provide information on the age at which Steve Denton began playing tennis in comparison to Albert Costa?\\n4. In terms of their tennis career beginnings, when did Steve Denton commence his training, and how does it compare to Albert Costa's start at the age of five?\\n5. Between Steve Denton and Albert Costa, who is known for having a late start or an early start in their tennis journey, specifically at the age of five?\\n6. What is the significance of the age of five in the development of Steve Denton's and Albert Costa's tennis careers, and which player started at that age?\", 'cot': \"Passage: The tennis player who started playing at the tender age of five was Albert Costa, out of the two mentioned players, Steve Denton and Albert Costa. Albert's early beginning with the sport at such a young age marked a significant headstart compared to Steve, who had a later start in his tennis journey. While的具体年龄对比史蒂夫·邓顿何时开始训练的信息并未在问题中给出，但可以确定的是，他的起步时间显然晚于Albert Costa，后者在五岁时就已经展开了网球训练。因此，在网球生涯的早期阶段，阿尔伯特·科斯塔以五岁这个年龄为分水岭，展现出了明显的优势。\", 'answer': 'Costa'}, {'question': 'What company produced both The Little Mermaid and The Strongest Man in the World?', 'elements': 'company, The Little Mermaid, The Strongest Man in the World.', 'questions': '1. What company is responsible for producing \"The Little Mermaid\"?\\n2. Which company is known for creating \"The Strongest Man in the World\"?\\n3. Which animation or film production company had a role in both \"The Little Mermaid\" and \"The Strongest Man in the World\"?\\n4. What company\\'s portfolio includes both these beloved films, \"The Little Mermaid\" and \"The Strongest Man in the World\"?\\n5. Why is this particular company associated with the production of both these well-known movies?\\n6. When did the company produce \"The Little Mermaid\" and \"The Strongest Man in the World,\" and how does that period relate to their overall filmography?', 'cot': 'Passage: \"The Little Mermaid\" and \"The Strongest Man in the World\" are both iconic productions from the renowned animation and film company, Disney. Known for its creativity and storytelling prowess, Disney is responsible for bringing these beloved characters to life. The period during which these films were produced, the late 20th century, showcases a significant chapter in Disney\\'s extensive filmography, as it marked a golden era for animated features. \"The Little Mermaid,\" released in 1989, and \"The Strongest Man in the World,\" which was part of the Walt Disney anthology film series, \"Fantasia\" (1940), demonstrate the company\\'s ability to captivate audiences with timeless classics that continue to resonate with viewers today.\"', 'answer': 'Walt Disney'}]\n"
     ]
    }
   ],
   "source": [
    "#对于hoptpot\n",
    "# 在语料库中，随机采样\n",
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import dashscope\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from utils import *\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def get_sentence_encoder():\n",
    "    model = \"all-MiniLM-L6-v2\"\n",
    "    return SentenceTransformer(model)\n",
    "encoder = get_sentence_encoder()\n",
    "#当前question属于cluster_id\": 0\n",
    "question = \"Seven years before the opening of the Brewer Fieldhouse in Columbia, Missouri, where was Chester Brewer working as head football coach and head basketball coach?\"\n",
    "question_embedding = encoder.encode(question)\n",
    "dataset_path = './demos/hotpot/demo_embedding.json'\n",
    "demo_num = 3\n",
    "cluster_id = 0\n",
    "\n",
    "#读取该任务的语料库\n",
    "with open(dataset_path, 'r',encoding=\"utf-8\") as f:\n",
    "    demo_datas = json.load(f)\n",
    "\n",
    "allsample = []\n",
    "for i in range(len(demo_datas)):\n",
    "        samples = demo_datas[i]['train_samples']\n",
    "        for j in range(len(samples)):\n",
    "            allsample.append(samples[j])\n",
    "\n",
    "random_samples = random.sample(allsample,demo_num)\n",
    "# print(random_samples)\n",
    "\n",
    "# 选择3个问题\n",
    "question_demonstrations = []\n",
    "for sample in random_samples:\n",
    "    sample_pre = {\n",
    "    \"question\" : sample[\"question\"],\n",
    "    \"elements\" : sample[\"elements\"],\n",
    "    \"questions\" : sample[\"questions\"],\n",
    "    \"cot\" : sample[\"cot\"],\n",
    "    \"answer\" : sample[\"gold_ans\"]\n",
    "    }\n",
    "    question_demonstrations.append(sample_pre)\n",
    "print(\"*************question_demonstrations***********\")\n",
    "print(question_demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! The United States of America is located in North America.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"0\",\n",
    "    base_url=\"http://192.168.0.35:8000/v1\",\n",
    ")\n",
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"hello, where is USA\"})\n",
    "# 单模型加载时模型名无意义，所以可以使用任何值\n",
    "result = client.chat.completions.create(messages=messages, model=\"qwen\")\n",
    "print(result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
